# Hotspotizer

The full manuscript for the master's thesis can be found under the [Releases section of the thesis repository](https://github.com/mbaytas/thesis/releases).

### Abstract

Devices that sense the alignment and motion of human limbs via computer vision have recently become a commodity; enabling a variety of novel user interfaces that use human gesture as the main input modality. The design and development of these interfaces requires programming tools that support the representation, creation and manipulation of information on human body gestures. Following concerns such as usability and physical differences among individuals, these tools should ideally target end-users and designers as well as professional software developers.

This thesis documents the design, development, deployment and evaluation of a software application to support gesture authoring by end-users for skeletal tracking vision-based input devices. The software enables end-users without programming experience to introduce gesture control to computing applications that serve their own goals; and provides developers and designers of gestural interfaces with a rapid prototyping tool that can be used to experientially evaluate designs.

### Keywords

Hotspotizer; gestural interaction; gesture authoring; visual programming; end-user development; interface prototyping; mid-air gestures; perceptual interaction; Kinect.

### Related Links

- [Master's Thesis: End-User Authoring of Mid-Air Gestural Interactions (TeX source)](https://github.com/mbaytas/thesis)
- [Koç University Design Lab](http://designlab.ku.edu.tr/)
- [Hotspotizer Project Page](http://designlab.ku.edu.tr/design-thinking-research-group/hotspotizer/)
- [Hotspotizer featured on Channel 9 Coding4Fun Kinect Projects blog](http://channel9.msdn.com/coding4fun/kinect/Todays-hot-project-Hotspotizer)

### Related Academic Publications

- Mehmet Aydın Baytaş, Yücel Yemez, and Oğuzhan Özcan (2014). Hotspotizer: end-user authoring of mid-air gestural interactions. In *Proceedings of the 8th Nordic Conference on Human-Computer Interaction (NordiCHI '14)*.
- Mehmet Aydın Baytaş, Yücel Yemez and Oğuzhan Özcan (2014). User Interface Paradigms for Visually Authoring Mid-Air Gestures: A Survey and a Provocation. In *Proceedings of the Workshop on Engineering Gestures for Multimodal Interfaces (EGMI 2014)*.

## IP stuff

The content of this repository is subject to Koç University's policies on intellectual property rights (see [here](http://gsssh.ku.edu.tr/rules-regulations) and [here](http://vprd.ku.edu.tr/research/grand)). Various bits and pieces that have somehow become part of the repository may be subject to various other policies, which should be indicated where relevant. Please observe these policies, along with some basic principles of academic honesty and common human decency, as you make use of this repository.

Conversely; if my work somehow makes use of content that belongs to you (or an organization you are affiliated with), in a way that you (or the organization you are affiliated with) do(es) not condone; please let me know, and I will do my best to observe your policies.
